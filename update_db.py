import requests
import pdfplumber
import pandas as pd
import sqlite3
import urllib3
import os
from datetime import datetime

# ğŸ”‡ å¿½ç•¥å®‰å…¨æ†‘è­‰è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

PDF_URL = "https://www-ws.gov.taipei/Download.ashx?u=LzAwMS9VcGxvYWQvNTEwL3JlbGZpbGUvMjUyMTYvODExOTIzNC80MjkzNWE2MS1mOTZmLTRmMjEtODUzYS01NmRlZTY3MmU0M2YucGRm&n=VENILVFQLTcuMi0xLSgxKeaOoeaqouaJi%2bWGii5wZGY%3d&icon=..pdf"
DB_NAME = "lab_test.db"

def update_job():
    print(f"[{datetime.now()}] ğŸ¤– GitHub Action æ©Ÿå™¨äººå•Ÿå‹•ï¼é–‹å§‹æ›´æ–°è³‡æ–™...")
    
    pdf_filename = "hospital_manual.pdf"
    
    # ä¸‹è¼‰
    try:
        response = requests.get(PDF_URL, timeout=60, verify=False) 
        with open(pdf_filename, 'wb') as f:
            f.write(response.content)
        print("âœ… PDF ä¸‹è¼‰å®Œæˆã€‚")
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return

    all_data = []
    
    # è§£æç¬¬ 68-101 é ï¼ˆç´¢å¼• 67-100ï¼‰
    try:
        with pdfplumber.open(pdf_filename) as pdf:
            start_page_index = 67  # ç¬¬ 68 é 
            end_page_index = 101   # ç¬¬ 101 é 
            total_pages = len(pdf.pages)
            
            print(f"ğŸ“„ PDF ç¸½é æ•¸: {total_pages}")
            print(f"ğŸ“– è§£æç¯„åœ: ç¬¬ 68-101 é  (ç´¢å¼• {start_page_index}-{end_page_index})")
            
            if start_page_index < total_pages:
                # å–å¾—æŒ‡å®šé é¢ç¯„åœ
                target_pages = pdf.pages[start_page_index:min(end_page_index + 1, total_pages)]
                print(f"âœ“ å¯¦éš›è§£æé æ•¸: {len(target_pages)}")
                
                for idx, page in enumerate(target_pages, start=start_page_index + 1):
                    tables = page.extract_tables()
                    if tables:
                        for table in tables:
                            if not table: 
                                continue
                            for row in table:
                                clean_row = [str(cell).strip() if cell is not None else "" for cell in row]
                                all_data.append(clean_row)
                        print(f"  âœ“ ç¬¬ {idx + 1} é : è§£ææˆåŠŸ")
                    else:
                        print(f"  âš  ç¬¬ {idx + 1} é : ç„¡è¡¨æ ¼")
    except Exception as e:
        print(f"âŒ è§£æéŒ¯èª¤: {e}")
        return

    # å­˜æª”
    if all_data:
        try:
            df = pd.DataFrame(all_data)
            df = df.replace(r'^\s*$', None, regex=True)
            df = df.ffill()
            df.columns = [f"æ¬„ä½_{i}" for i in range(len(df.columns))]
            
            conn = sqlite3.connect(DB_NAME)
            df.to_sql('tests', conn, if_exists='replace', index=False)
            conn.close()
            print(f"ğŸ‰ è³‡æ–™åº«æ›´æ–°æˆåŠŸï¼å…± {len(df)} ç­†ã€‚")
        except Exception as e:
            print(f"âŒ è³‡æ–™åº«éŒ¯èª¤: {e}")
    else:
        print("âš ï¸ æœªæŠ“åˆ°è³‡æ–™ã€‚")

if __name__ == "__main__":
    update_job()
