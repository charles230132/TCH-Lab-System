import streamlit as st
import pandas as pd
import sqlite3
import re
from typing import List, Dict, Optional

# ==================== é…ç½® ====================
DB_FILE = "lab_test.db"
CACHE_TTL = 600

# ç„¡æ•ˆå€¼é›†åˆ
INVALID_VALUES = {'ç„¡', 'None', 'nan', 'null', '', '*'}
HOSPITAL_NAMES = {'å¿ å­', 'ä»æ„›', 'å’Œå¹³', 'é™½æ˜', 'ä¸­èˆˆ', 'æ¾å¾·', 'æ—æ£®', 'å©¦å¹¼'}

# ==================== ç¶²é è¨­å®š ====================
st.set_page_config(
    page_title="TCH æª¢é©—æŸ¥è©¢", 
    page_icon="ğŸ¥", 
    layout="wide"
)

# ==================== å…è²¬è²æ˜ ====================
DISCLAIMER = """
âš ï¸ **å…è²¬è²æ˜**

æœ¬æ‡‰ç”¨ç³»çµ±åƒ…ä¾›åƒè€ƒä¹‹ç”¨ï¼Œä¸æ§‹æˆä»»ä½•é†«ç™‚å»ºè­°ã€‚ä½¿ç”¨è€…å› ä½¿ç”¨æœ¬ç³»çµ±æ‰€ç”¢ç”Ÿçš„ä»»ä½•æå®³ã€æå¤±æˆ–å‚·å®³ï¼Œæœ¬æ‡‰ç”¨é–‹ç™¼è€…ä¸æ‰¿æ“”ä»»ä½•è²¬ä»»ã€‚

- æœ¬ç³»çµ±æä¾›çš„æª¢é©—è³‡æ–™ä¾†æºæ–¼è³‡æ–™åº«ï¼Œå¯èƒ½å­˜åœ¨èª¤å·®æˆ–å»¶é²
- æª¢é©—çµæœçš„è§£é‡‹éœ€ç”±åˆæ ¼çš„é†«ç™‚å°ˆæ¥­äººå£«é€²è¡Œè©•ä¼°
- æ‚£è€…æ‡‰å°±é†«ç™‚ç›¸é—œå•é¡Œå’¨è©¢å…¶ä¸»æ²»é†«ç”Ÿæˆ–å°ˆç§‘é†«ç”Ÿ
- ä»»ä½•é†«ç™‚æ±ºå®šæ‡‰åŸºæ–¼å…¨é¢çš„è‡¨åºŠè©•ä¼°ï¼Œè€Œä¸æ‡‰åƒ…ä¾è³´æœ¬ç³»çµ±
- æœ¬æ‡‰ç”¨ä¸å°è³‡æ–™çš„æº–ç¢ºæ€§ã€å®Œæ•´æ€§æˆ–åŠæ™‚æ€§åšå‡ºä»»ä½•ä¿è­‰

ä½¿ç”¨æœ¬ç³»çµ±å³è¡¨ç¤ºæ‚¨å·²åŒæ„ä¸Šè¿°å…è²¬è²æ˜ã€‚
"""

# ==================== CSS æ¨£å¼ ====================
st.markdown("""
<style>
    [data-testid="stHeader"], footer { 
        visibility: hidden; 
    }
    
    div[data-testid="stTable"] {
        font-size: 1rem;
        overflow: visible !important;
        height: auto !important;
    }
    
    div[data-testid="stTable"] td {
        white-space: pre-wrap !important;
        word-wrap: break-word !important;
        vertical-align: top !important;
        min-width: 100px;
        line-height: 1.6;
        padding: 8px !important;
    }
    
    div[data-testid="stTable"] th {
        white-space: nowrap !important;
        background-color: #f0f2f6 !important;
        font-weight: bold !important;
        padding: 10px !important;
    }
    
    div[data-testid="stTextInput"] > div > div > input {
        font-size: 1.1rem;
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# ==================== è³‡æ–™åº«æ“ä½œ ====================
@st.cache_data(ttl=CACHE_TTL)
def load_data() -> pd.DataFrame:
    """è¼‰å…¥è³‡æ–™åº«æ•¸æ“š"""
    try:
        with sqlite3.connect(DB_FILE) as conn:
            df = pd.read_sql("SELECT * FROM tests", conn)
            return df.fillna("")
    except Exception as e:
        st.error(f"âŒ è³‡æ–™åº«è¼‰å…¥å¤±æ•—: {e}")
        return pd.DataFrame()

def get_db_last_update() -> str:
    """å–å¾—è³‡æ–™åº«æœ€å¾Œæ›´æ–°æ™‚é–“"""
    try:
        import os
        if os.path.exists(DB_FILE):
            mod_time = os.path.getmtime(DB_FILE)
            from datetime import datetime
            update_time = datetime.fromtimestamp(mod_time)
            return update_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        else:
            return "å°šæœªå»ºç«‹"
    except Exception as e:
        return f"ç„¡æ³•å–å¾— ({e})"

# ==================== è¼”åŠ©å‡½æ•¸ ====================
def is_valid_value(value: str) -> bool:
    """æª¢æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆ"""
    if not value or value.lower() in INVALID_VALUES:
        return False
    if value in HOSPITAL_NAMES:
        return False
    if re.match(r'^\d+(\.\d+)?\s*%?$', value):
        return False
    if re.match(r'^\d{1,2}$', value):
        return False
    return True

def is_reference_value(text: str) -> bool:
    """åˆ¤æ–·æ–‡å­—æ˜¯å¦ç‚ºåƒè€ƒå€¼æ ¼å¼"""
    if not text:
        return False
    return (re.match(r'^[0-9]', text) or 
            any(indicator in text.lower() for indicator in ['<', '>', 'mg/dl', 'u/l', 'mmol']))

def clean_text(text: str, remove_newlines: bool = True) -> str:
    """æ¸…ç†æ–‡å­—"""
    text = str(text).strip()
    if remove_newlines:
        text = text.replace('\n', ' ')
        text = re.sub(r'\s+', ' ', text)
    return text

def extract_clinical_notes(row: pd.Series) -> str:
    """æå–è‡¨åºŠæ„ç¾©"""
    notes = []
    
    clinical_cols = sorted(
        [c for c in row.index if c.startswith('æ¬„ä½_') and int(c.split('_')[1]) >= 10],
        key=lambda x: int(x.split('_')[1])
    )
    
    for col in clinical_cols:
        val = str(row.get(col, '')).strip()
        
        if not is_valid_value(val):
            continue
        
        if any(keyword in val for keyword in ['è‡¨åºŠæ„ç¾©', 'åƒè€ƒå€¼']):
            continue
        
        if not re.search(r'[\u4e00-\u9fff]', val):
            continue
        
        notes.append(val)
    
    return "\n".join(notes) if notes else "ç„¡"

def is_garbage_row(clinical_text: str, en_name: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦ç‚ºåƒåœ¾è¡Œ"""
    if "D-Dimer" in clinical_text and "D-Dimer" not in en_name:
        return True
    
    if "è¡€å‹" in clinical_text and not any(word in en_name for word in ["Blood", "Type"]):
        return True
    
    return False

# ==================== æœå°‹é‚è¼¯ï¼ˆæ”¹é€²ç‰ˆï¼‰====================
def search_data(df: pd.DataFrame, search_term: str) -> pd.DataFrame:
    """åŸ·è¡Œæœå°‹ä¸¦è™•ç†æ•¸æ“š - æ”¹é€²ç‰ˆæ”¯æ´æ¨¡ç³Šæœå°‹"""
    
    # æ¸…ç†æœå°‹è©ï¼šç§»é™¤å¤šé¤˜ç©ºç™½
    search_term_clean = ' '.join(search_term.strip().split())
    
    # è½‰å°å¯«ç”¨æ–¼ä¸å€åˆ†å¤§å°å¯«æœå°‹
    search_lower = search_term_clean.lower()
    
    # å»ºç«‹å¤šç¨®æœå°‹ç­–ç•¥
    masks = []
    
    # ç­–ç•¥1: ç›´æ¥åŒ…å«æœå°‹ï¼ˆä¸å€åˆ†å¤§å°å¯«ï¼‰
    for col in ['æ¬„ä½_0', 'æ¬„ä½_1', 'æ¬„ä½_2', 'æ¬„ä½_3']:
        mask = df[col].astype(str).str.lower().str.contains(search_lower, case=False, na=False, regex=False)
        masks.append(mask)
    
    # ç­–ç•¥2: å¦‚æœæœå°‹è©åŒ…å«ç©ºæ ¼ï¼Œä¹Ÿæœå°‹å»é™¤ç©ºæ ¼çš„ç‰ˆæœ¬
    if ' ' in search_term_clean:
        search_no_space = search_term_clean.replace(' ', '').lower()
        for col in ['æ¬„ä½_0', 'æ¬„ä½_1', 'æ¬„ä½_2', 'æ¬„ä½_3']:
            mask = df[col].astype(str).str.lower().str.replace(' ', '').str.contains(search_no_space, case=False, na=False, regex=False)
            masks.append(mask)
    
    # ç­–ç•¥3: åˆ†è©æœå°‹ï¼ˆæ‰€æœ‰è©éƒ½è¦å‡ºç¾ï¼‰
    words = search_term_clean.lower().split()
    if len(words) > 1:
        for col in ['æ¬„ä½_1', 'æ¬„ä½_2']:  # åªåœ¨ä¸­è‹±æ–‡åç¨±ä¸­ä½¿ç”¨
            word_masks = [df[col].astype(str).str.lower().str.contains(word, case=False, na=False, regex=False) for word in words]
            if word_masks:
                combined_mask = word_masks[0]
                for m in word_masks[1:]:
                    combined_mask = combined_mask & m
                masks.append(combined_mask)
    
    # åˆä½µæ‰€æœ‰æœå°‹çµæœ
    final_mask = masks[0] if masks else pd.Series([False] * len(df))
    for mask in masks[1:]:
        final_mask = final_mask | mask
    
    return df[final_mask].copy()

def process_row(row: pd.Series) -> Optional[Dict[str, str]]:
    """è™•ç†å–®è¡Œæ•¸æ“š"""
    code = clean_text(row.get('æ¬„ä½_0', ''), remove_newlines=True)
    zh_name = clean_text(row.get('æ¬„ä½_1', ''), remove_newlines=True)
    en_name = clean_text(row.get('æ¬„ä½_2', ''), remove_newlines=True)
    
    raw_col3 = str(row.get('æ¬„ä½_3', '')).strip()
    raw_col4 = str(row.get('æ¬„ä½_4', '')).strip()
    raw_col5 = str(row.get('æ¬„ä½_5', '')).strip()
    raw_col6 = str(row.get('æ¬„ä½_6', '')).strip()
    raw_col9 = str(row.get('æ¬„ä½_9', '')).strip()
    
    # çµ„å¥—ç´°é …
    sub_item = "ç„¡"
    if raw_col3 and raw_col3 not in INVALID_VALUES:
        cleaned_col3 = re.sub(r'^\d+\s+', '', raw_col3).strip()
        
        if 'CBC' in cleaned_col3 and 'é …ç›®' in cleaned_col3:
            return None
        
        if cleaned_col3 not in ['è¡€æ¸…', 'è¡€æ¼¿', 'å…¨è¡€', 'å°¿', 'CSF', 'èƒ¸æ°´', 'è…¹æ°´', '']:
            if cleaned_col3.lower() != 'negative':
                if not is_reference_value(cleaned_col3):
                    sub_item = cleaned_col3
    
    # å¹´é½¡
    age = "ç„¡"
    if raw_col4 and any(indicator in raw_col4 for indicator in ['æ­²', 'å¤©', 'M', 'F', 'year', 'day', 'month', '~', 'å¤©-']):
        age = raw_col4
    
    # åƒè€ƒå€¼
    ref_value = "ç„¡"
    if sub_item == "ç„¡" and raw_col3 and is_reference_value(raw_col3):
        ref_value = raw_col3
    else:
        candidates = [raw_col5, raw_col6, raw_col9]
        for candidate in candidates:
            if not candidate or candidate in INVALID_VALUES:
                continue
            if candidate in HOSPITAL_NAMES:
                continue
            
            if is_reference_value(candidate) or candidate.lower() in ['negative', 'positive']:
                if ref_value == "ç„¡":
                    ref_value = candidate
                else:
                    if candidate not in ref_value:
                        ref_value += f" | {candidate}"
                break
    
    # è‡¨åºŠæ„ç¾©
    clinical = extract_clinical_notes(row)
    
    if is_garbage_row(clinical, en_name):
        return None
    
    if sub_item == "ç„¡" and age == "ç„¡" and ref_value == "ç„¡" and clinical == "ç„¡":
        return None
    
    return {
        "å¥ä¿ä»£ç¢¼": code,
        "ä¸­æ–‡åç¨±": zh_name,
        "è‹±æ–‡åç¨±": en_name,
        "çµ„å¥—ç´°é …": sub_item,
        "å¹´é½¡": age,
        "åƒè€ƒå€¼": ref_value,
        "è‡¨åºŠæ„ç¾©": clinical
    }

# ==================== ä¸»ç¨‹å¼ ====================
def main():
    st.title("ğŸ¥ æª¢é©—é …ç›®æŸ¥è©¢ç³»çµ±")
    
    with st.expander("ğŸ“‹ æŸ¥çœ‹å…è²¬è²æ˜", expanded=False):
        st.markdown(DISCLAIMER)
    
    st.markdown("---")
    
    df = load_data()
    
    if df.empty:
        st.error("âŒ è³‡æ–™åº«æ˜¯ç©ºçš„ï¼Œè«‹å…ˆåŸ·è¡Œ update_db.py")
        return
    
    last_update = get_db_last_update()
    st.info(f"ğŸ“… è³‡æ–™åº«æœ€å¾Œæ›´æ–°æ™‚é–“ï¼š{last_update}")
    
    search_term = st.text_input(
        "ğŸ” è«‹è¼¸å…¥æª¢é©—ä»£ç¢¼æˆ–é—œéµå­—ï¼š",
        "",
        placeholder="ä¾‹å¦‚ï¼šTotal Protein, AFP, ç¸½è›‹ç™½, 09026...",
        help="å¯æœå°‹å¥ä¿ä»£ç¢¼ã€ä¸­æ–‡åç¨±ã€è‹±æ–‡åç¨±æˆ–çµ„å¥—ç´°é …ã€‚æ”¯æ´æ¨¡ç³Šæœå°‹ã€‚"
    )
    
    if not search_term:
        st.info("ğŸ’¡ è«‹åœ¨ä¸Šæ–¹è¼¸å…¥æœå°‹é—œéµå­—é–‹å§‹æŸ¥è©¢")
        st.info("ğŸ” æœå°‹æç¤ºï¼š\n- æ”¯æ´ä¸­è‹±æ–‡æ··åˆæœå°‹\n- ä¸å€åˆ†å¤§å°å¯«\n- å¯ä½¿ç”¨ç©ºæ ¼åˆ†éš”å¤šå€‹é—œéµå­—")
        return
    
    with st.spinner("ğŸ” æœå°‹ä¸­..."):
        result_df = search_data(df, search_term)
    
    if result_df.empty:
        st.warning(f"âš ï¸ æŸ¥ç„¡ã€Œ{search_term}ã€ç›¸é—œè³‡æ–™")
        st.info("ğŸ’¡ æœå°‹å»ºè­°ï¼š\n- æª¢æŸ¥æ˜¯å¦æœ‰æ‹¼å¯«éŒ¯èª¤\n- å˜—è©¦ä½¿ç”¨éƒ¨åˆ†é—œéµå­—ï¼ˆå¦‚ï¼šprotein, è›‹ç™½ï¼‰\n- ä½¿ç”¨å¥ä¿ä»£ç¢¼æœå°‹æ›´ç²¾ç¢º")
        return
    
    display_rows = []
    for _, row in result_df.iterrows():
        processed = process_row(row)
        if processed:
            display_rows.append(processed)
    
    if not display_rows:
        st.warning("âš ï¸ æŸ¥ç„¡è³‡æ–™ï¼ˆæœ‰æ•ˆè³‡æ–™éæ¿¾å¾Œç‚ºç©ºï¼‰ã€‚")
        return
    
    final_df = pd.DataFrame(display_rows).drop_duplicates()
    
    st.success(f"âœ… æ‰¾åˆ° {len(final_df)} ç­†çµæœ")
    
    for idx, row in final_df.iterrows():
        with st.expander(f"ğŸ“‹ {row['ä¸­æ–‡åç¨±']} ({row['è‹±æ–‡åç¨±']}) - {row['å¥ä¿ä»£ç¢¼']}", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**å¥ä¿ä»£ç¢¼ï¼š** {row['å¥ä¿ä»£ç¢¼']}")
                st.markdown(f"**ä¸­æ–‡åç¨±ï¼š** {row['ä¸­æ–‡åç¨±']}")
                st.markdown(f"**è‹±æ–‡åç¨±ï¼š** {row['è‹±æ–‡åç¨±']}")
                st.markdown(f"**çµ„å¥—ç´°é …ï¼š** {row['çµ„å¥—ç´°é …']}")
            
            with col2:
                st.markdown(f"**å¹´é½¡ï¼š** {row['å¹´é½¡']}")
                st.markdown(f"**åƒè€ƒå€¼ï¼š** {row['åƒè€ƒå€¼']}")
            
            st.markdown("---")
            st.markdown(f"**è‡¨åºŠæ„ç¾©ï¼š**\n\n{row['è‡¨åºŠæ„ç¾©']}")

if __name__ == "__main__":
    main()
